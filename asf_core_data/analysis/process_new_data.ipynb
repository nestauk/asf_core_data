{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for producing processed EPC and MCS data and merging them into one table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the asf-core-data repo for the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "from asf_core_data import generate_and_save_mcs\n",
    "from asf_core_data import load_preprocessed_epc_data\n",
    "\n",
    "from asf_core_data.getters.epc import data_batches\n",
    "from asf_core_data.getters.data_getters import download_core_data\n",
    "\n",
    "from asf_core_data.pipeline.preprocessing import preprocess_epc_data\n",
    "from asf_core_data.pipeline.data_joining import install_date_computation, merge_proc_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing EPC\n",
    "\n",
    "Currently, we're still handling the EPC processing by downloading and processing it locally. In the future, this will be done directly via S3. \n",
    "For now, we need to download the raw EPC data into our local data foler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_DIR = '/path/to/data/dir'\n",
    "\n",
    "\n",
    "if not os.path.exists(LOCAL_DATA_DIR):\n",
    "    os.makedirs(LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_core_data('epc_raw', LOCAL_DATA_DIR, batch='newest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local input dir\n",
      "---------------\n",
      "Available batches: ['2021_Q2_0721', '2022_Q1_complete', '2021_Q4_0721', '2020_Q3_1220', '2022_Q3_complete']\n",
      "Newest batch: 2022_Q3_complete\n"
     ]
    }
   ],
   "source": [
    "# Check whether newest batch shows up a newest in local data dir\n",
    "print(\"Local input dir\\n---------------\")\n",
    "print(\"Available batches:\", data_batches.get_all_batch_names(data_path=LOCAL_DATA_DIR, check_folder='inputs'))\n",
    "print(\"Newest batch:\", data_batches.get_most_recent_epc_batch(data_path=LOCAL_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process new batch of EPC data\n",
    "epc_full = preprocess_epc_data.load_and_preprocess_epc_data(\n",
    "    data_path=LOCAL_DATA_DIR, batch=\"newest\", subset='GB',\n",
    "    reload_raw=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing MCS\n",
    "\n",
    "After processing the EPC data, it has to be uploaded to S3 again for further processing. In the future, this will happen automatically.\n",
    "In order for the following code to work, you should at least upload the following file to the S3 asf-core-data bucket: `LOCAL_DATA_DIR/BATCH_NAME/EPC_GB_preprocessed.csv`\n",
    "\n",
    "You can do this using a command as the following in your terminal:\n",
    "\n",
    "`aws s3 cp LOCAL_DATA_DIR/outputs/EPC/preprocessed_data/2022_Q3_complete/EPC_GB_preprocessed.csv s3://asf-core-data/outputs/EPC/preprocessed_data/2022_Q3_complete/`\n",
    "\n",
    "\n",
    "**Note:**\n",
    "An additional step will be added here or included in `generate_and_save_mcs()`. We will need to process the MCS historical installer data and add the unique installation ID to the MCS installations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to process MCS data and join it with EPC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installations files\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2021.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q1.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q2.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q3.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q4.xlsx\n",
      "\n",
      "Installer files\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q1.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installer_information_2022_04_06.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installer_information_2022_07_25.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installers.xlsx\n",
      "Number of records before removing duplicates: 178248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/mcs/generate_mcs_data.py:136: UserWarning: Not all installation file columns are the same.\n",
      "  warnings.warn(\"Not all installation file columns are the same.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after removing duplicates: 178200\n",
      "Shape of loaded data: (176524, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/mcs/process/process_mcs_installations.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hps[\"cluster\"].loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in S3: /outputs/MCS/mcs_installations_230315.csv\n",
      "Getting EPC data...\n",
      "Forming a matching...\n",
      "- Forming an index...\n",
      "- Forming a comparison...\n",
      "- Computing a matching...\n",
      "Joining the data...\n",
      "After joining:\n",
      "-----------------\n",
      "Total records: 277493\n",
      "Number matched with EPC: 246186\n",
      "\n",
      "\n",
      "Saved in S3: /outputs/MCS/mcs_installations_epc_full_230315.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/mcs/process/mcs_epc_joining.py:372: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  joined_df[\"last_epc_before_mcs\"].iloc[last_epc_before_mcs_indices] = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in S3: /outputs/MCS/mcs_installations_epc_most_relevant_230315.csv\n"
     ]
    }
   ],
   "source": [
    "# Get MCS and join with MCS\n",
    "generate_and_save_mcs(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the EPC and MCS\n",
    "\n",
    "Finally, we load the EPC data and merge it with the MCS installations data for computing the best approximation for a heat pump installation date. You can also load the data from 'S3' insteadl of the local data dir, but if you have it downloaded it's faster.\n",
    "\n",
    "All these steps are summarised in the function `merging_pipeline()` in `merge_proc_datasets.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 02:21:40,785 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Load the processed EPC data \n",
    "prep_epc = load_preprocessed_epc_data(data_path=\"S3\", version='preprocessed',\n",
    "                                       #usecols=['UPRN', 'INSPECTION_DATE', 'HP_INSTALLED', 'HP_TYPE'],  # use fewer fields for testing to save time\n",
    "                                       batch='newest'\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"FIRST_HP_MENTION\"] = df[identifier].map(dict(first_hp_mention))\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"MCS_AVAILABLE\"] = ~df[\"HP_INSTALL_DATE\"].isna()\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HAS_HP_AT_SOME_POINT\"] = ~df[\"FIRST_HP_MENTION\"].isna()\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ARTIFICIALLY_DUPL\"] = False\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"EPC HP entry before MCS\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:240: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:243: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:254: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"No EPC HP entry after MCS\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:262: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19047896, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more precise estimations for heat pump installation dates via MCS data\n",
    "epc_with_MCS_dates = install_date_computation.compute_hp_install_date(\n",
    "    prep_epc\n",
    ")\n",
    "\n",
    "epc_with_MCS_dates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EPC data with enhanced installation dates can then be merged with MCS installation data. This will standardise features such as HP_INSTALLED and HP_TYPE.\n",
    "\n",
    "**Note**: We're excluding two missing features (\"company_unique_id\", \"installer_name\") until the final merges are complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPC (19047896, 65)\n",
      "MCS (176524, 13)\n",
      "MCS (EPC matched) (145217, 13)\n",
      "MCS (EPC unmatched) (31307, 13)\n",
      "EPC and MCS merged (19085300, 75)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['BUILDING_REFERENCE_NUMBER', 'UPRN', 'ADDRESS1', 'ADDRESS2', 'POSTCODE',\n",
       "       'INSPECTION_DATE', 'ENERGY_CONSUMPTION_CURRENT', 'TOTAL_FLOOR_AREA',\n",
       "       'CURRENT_ENERGY_EFFICIENCY', 'CURRENT_ENERGY_RATING',\n",
       "       'POTENTIAL_ENERGY_RATING', 'CO2_EMISS_CURR_PER_FLOOR_AREA',\n",
       "       'WALLS_DESCRIPTION', 'WALLS_ENERGY_EFF', 'ROOF_DESCRIPTION',\n",
       "       'ROOF_ENERGY_EFF', 'FLOOR_DESCRIPTION', 'FLOOR_ENERGY_EFF',\n",
       "       'WINDOWS_DESCRIPTION', 'WINDOWS_ENERGY_EFF', 'MAINHEAT_DESCRIPTION',\n",
       "       'MAINHEAT_ENERGY_EFF', 'MAINHEATC_ENERGY_EFF', 'SECONDHEAT_DESCRIPTION',\n",
       "       'HOTWATER_DESCRIPTION', 'HOT_WATER_ENERGY_EFF', 'LIGHTING_DESCRIPTION',\n",
       "       'LIGHTING_ENERGY_EFF', 'CO2_EMISSIONS_CURRENT', 'CONSTRUCTION_AGE_BAND',\n",
       "       'LOW_ENERGY_LIGHTING', 'FLOOR_LEVEL', 'GLAZED_AREA',\n",
       "       'NUMBER_HABITABLE_ROOMS', 'LOCAL_AUTHORITY_LABEL', 'MAINS_GAS_FLAG',\n",
       "       'MAIN_HEATING_CONTROLS', 'ENERGY_TARIFF', 'MULTI_GLAZE_PROPORTION',\n",
       "       'GLAZED_TYPE', 'PHOTO_SUPPLY', 'SOLAR_WATER_HEATING_FLAG', 'TENURE',\n",
       "       'TRANSACTION_TYPE', 'BUILT_FORM', 'PROPERTY_TYPE', 'COUNTRY', 'LMK_KEY',\n",
       "       'LOCAL_AUTHORITY', 'N_SAME_UPRN_ENTRIES', 'HEATING_SYSTEM',\n",
       "       'HEATING_FUEL', 'HP_INSTALLED', 'HP_TYPE', 'CURR_ENERGY_RATING_NUM',\n",
       "       'ENERGY_RATING_CAT', 'DIFF_POT_ENERGY_RATING', 'HP_INSTALL_DATE',\n",
       "       'FIRST_HP_MENTION', 'MCS_AVAILABLE', 'HAS_HP_AT_SOME_POINT',\n",
       "       'ARTIFICIALLY_DUPL', 'EPC HP entry before MCS',\n",
       "       'No EPC HP entry after MCS', 'EPC_AVAILABLE', 'commission_date',\n",
       "       'capacity', 'estimated_annual_generation', 'tech_type', 'design',\n",
       "       'cost', 'product_name', 'manufacturer', 'flow_temp', 'scop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epc_mcs_processed = merge_proc_datasets.add_mcs_installations_data(epc_with_MCS_dates, usecols=[\n",
    "        \"UPRN\",\n",
    "        \"commission_date\",\n",
    "        \"capacity\",\n",
    "        \"estimated_annual_generation\",\n",
    "        \"flow_temp\",\n",
    "        \"tech_type\",\n",
    "        \"scop\",\n",
    "        \"design\",\n",
    "        \"product_name\",\n",
    "        \"manufacturer\",\n",
    "        \"cost\"\n",
    "    ], verbose=True)\n",
    "epc_mcs_processed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! This will fail until merge conflicts are resolved !\n",
    "\n",
    "This section will be tested and revised after the final merges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'company_unique_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge EPC/MCS with MCS installers \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m epc_mcs_complete \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_proc_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_mcs_installer_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepc_mcs_processed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m epc_mcs_complete\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/merge_proc_datasets.py:165\u001b[0m, in \u001b[0;36madd_mcs_installer_data\u001b[0;34m(df, usecols)\u001b[0m\n\u001b[1;32m    159\u001b[0m mcs_instllr_data \u001b[38;5;241m=\u001b[39m data_getters\u001b[38;5;241m.\u001b[39mload_s3_data(\n\u001b[1;32m    160\u001b[0m     base_config\u001b[38;5;241m.\u001b[39mBUCKET_NAME, newest_hist_inst_batch, usecols\u001b[38;5;241m=\u001b[39musecols\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m mcs_instllr_data\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostcode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTCODE\u001b[39m\u001b[38;5;124m\"\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 165\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmcs_instllr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompany_unique_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstaller_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompany_unique_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompany_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:9351\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9332\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9333\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   9334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9347\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   9348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9349\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m-> 9351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9352\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9360\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9361\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9365\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    696\u001b[0m (\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1110\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(rk)\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1110\u001b[0m     left_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1111\u001b[0m     join_names\u001b[38;5;241m.\u001b[39mappend(lk)\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:1840\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1838\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'company_unique_id'"
     ]
    }
   ],
   "source": [
    "# Merge EPC/MCS with MCS installers \n",
    "epc_mcs_complete = merge_proc_datasets.add_mcs_installer_data(\n",
    "    epc_mcs_processed)\n",
    "\n",
    "epc_mcs_complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat postcode field to include no space\n",
    "epc_mcs_complete = data_cleaning.reformat_postcode(\n",
    "    epc_mcs_complete, postcode_var_name=\"POSTCODE\", white_space=\"remove\"\n",
    ")\n",
    "epc_mcs_complete['POSTCODE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 11:51:27,171 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"FIRST_HP_MENTION\"] = df[identifier].map(dict(first_hp_mention))\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"MCS_AVAILABLE\"] = ~df[\"HP_INSTALL_DATE\"].isna()\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HAS_HP_AT_SOME_POINT\"] = ~df[\"FIRST_HP_MENTION\"].isna()\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ARTIFICIALLY_DUPL\"] = False\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"EPC HP entry before MCS\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:240: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:243: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:254: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"No EPC HP entry after MCS\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:262: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['company_unique_id']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m epc_mcs_combined \u001b[39m=\u001b[39m merge_proc_datasets\u001b[39m.\u001b[39;49mmerging_pipeline()\n",
      "File \u001b[0;32m~/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/merge_proc_datasets.py:209\u001b[0m, in \u001b[0;36mmerging_pipeline\u001b[0;34m(epc_usecols, mcs_installations_usecols, mcs_installers_usecols)\u001b[0m\n\u001b[1;32m    206\u001b[0m epc_with_MCS_dates \u001b[39m=\u001b[39m install_date_computation\u001b[39m.\u001b[39mcompute_hp_install_date(prep_epc)\n\u001b[1;32m    208\u001b[0m \u001b[39m# Merge EPC with MCS installations\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m epc_mcs_insts \u001b[39m=\u001b[39m add_mcs_installations_data(\n\u001b[1;32m    210\u001b[0m     epc_with_MCS_dates, usecols\u001b[39m=\u001b[39;49mmcs_installations_usecols\n\u001b[1;32m    211\u001b[0m )\n\u001b[1;32m    213\u001b[0m \u001b[39m# Merge EPC/MCS with MCS installers\u001b[39;00m\n\u001b[1;32m    214\u001b[0m epc_mcs_complete \u001b[39m=\u001b[39m add_mcs_installer_data(\n\u001b[1;32m    215\u001b[0m     epc_mcs_insts, usecols\u001b[39m=\u001b[39mmcs_installers_usecols\n\u001b[1;32m    216\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/merge_proc_datasets.py:57\u001b[0m, in \u001b[0;36madd_mcs_installations_data\u001b[0;34m(epc_df, usecols, bucket_name, verbose)\u001b[0m\n\u001b[1;32m     54\u001b[0m newest_joined_batch \u001b[39m=\u001b[39m data_batches\u001b[39m.\u001b[39mget_latest_mcs_epc_joined_batch()\n\u001b[1;32m     56\u001b[0m \u001b[39m# # Load MCS\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m mcs_df \u001b[39m=\u001b[39m data_getters\u001b[39m.\u001b[39;49mload_s3_data(\n\u001b[1;32m     58\u001b[0m     bucket_name,\n\u001b[1;32m     59\u001b[0m     newest_joined_batch,\n\u001b[1;32m     60\u001b[0m     usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m     61\u001b[0m     dtype\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mUPRN\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcommission_date\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     64\u001b[0m mcs_df \u001b[39m=\u001b[39m install_date_computation\u001b[39m.\u001b[39mreformat_mcs_date(mcs_df, \u001b[39m\"\u001b[39m\u001b[39mcommission_date\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m mcs_df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mpostcode\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPOSTCODE\u001b[39m\u001b[39m\"\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/repositories/asf_core_data/asf_core_data/getters/data_getters.py:239\u001b[0m, in \u001b[0;36mload_s3_data\u001b[0;34m(bucket_name, file_name, usecols, dtype, skiprows, n_samples, columns_to_parse_as_dates, encoding, low_memory)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[39mreturn\u001b[39;00m data[\u001b[39mlist\u001b[39m(data\u001b[39m.\u001b[39mkeys())[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[39melif\u001b[39;00m fnmatch(file_name, \u001b[39m\"\u001b[39m\u001b[39m*.csv\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[1;32m    240\u001b[0m         os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m\"\u001b[39;49m\u001b[39ms3://\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m bucket_name, file_name),\n\u001b[1;32m    241\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    242\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m    243\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    244\u001b[0m         low_memory\u001b[39m=\u001b[39;49mlow_memory,\n\u001b[1;32m    245\u001b[0m         skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[1;32m    246\u001b[0m         nrows\u001b[39m=\u001b[39;49mn_samples,\n\u001b[1;32m    247\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mcolumns_to_parse_as_dates,\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    250\u001b[0m \u001b[39melif\u001b[39;00m fnmatch(file_name, \u001b[39m\"\u001b[39m\u001b[39m*.geojson\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m gpd\u001b[39m.\u001b[39mread_file(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39ms3://\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m bucket_name, file_name))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1236\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1236\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1237\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:131\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols_dtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mset\u001b[39m(usecols)\u001b[39m.\u001b[39missubset(\n\u001b[1;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names\n\u001b[1;32m    130\u001b[0m ):\n\u001b[0;32m--> 131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_usecols_names(usecols, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49morig_names)\n\u001b[1;32m    133\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames) \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(usecols):  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py:913\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[0;34m(self, usecols, names)\u001b[0m\n\u001b[1;32m    911\u001b[0m missing \u001b[39m=\u001b[39m [c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m usecols \u001b[39mif\u001b[39;00m c \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m names]\n\u001b[1;32m    912\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 913\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    914\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    916\u001b[0m     )\n\u001b[1;32m    918\u001b[0m \u001b[39mreturn\u001b[39;00m usecols\n",
      "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['company_unique_id']"
     ]
    }
   ],
   "source": [
    "epc_mcs_combined = merge_proc_datasets.merging_pipeline()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "151bc73aaa639fad610cb4b2d60afec3c77157d89b4c3022086af37771d09181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
