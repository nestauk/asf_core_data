{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for producing processed EPC and MCS data and merging them into one table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the asf-core-data repo for the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "from asf_core_data import generate_and_save_mcs\n",
    "from asf_core_data import load_preprocessed_epc_data\n",
    "\n",
    "from asf_core_data.getters.epc import data_batches\n",
    "from asf_core_data.getters.data_getters import download_core_data\n",
    "\n",
    "from asf_core_data.pipeline.preprocessing import preprocess_epc_data\n",
    "from asf_core_data.pipeline.data_joining import install_date_computation, merge_proc_datasets\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing EPC\n",
    "\n",
    "Currently, we're still handling the EPC processing by downloading and processing it locally. In the future, this will be done directly via S3. \n",
    "For now, we need to download the raw EPC data into our local data foler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_DIR = '/path/to/data/dir'\n",
    "\n",
    "if not os.path.exists(LOCAL_DATA_DIR):\n",
    "    os.makedirs(LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_core_data('epc_raw', LOCAL_DATA_DIR, batch='newest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local input dir\n",
      "---------------\n",
      "Available batches: ['2021_Q2_0721', '2022_Q1_complete', '2021_Q4_0721', '2020_Q3_1220', '2022_Q3_complete']\n",
      "Newest batch: 2022_Q3_complete\n"
     ]
    }
   ],
   "source": [
    "# Check whether newest batch shows up a newest in local data dir\n",
    "print(\"Local input dir\\n---------------\")\n",
    "print(\"Available batches:\", data_batches.get_all_batch_names(data_path=LOCAL_DATA_DIR, check_folder='inputs'))\n",
    "print(\"Newest batch:\", data_batches.get_most_recent_epc_batch(data_path=LOCAL_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process new batch of EPC data\n",
    "epc_full = preprocess_epc_data.load_and_preprocess_epc_data(\n",
    "    data_path=LOCAL_DATA_DIR, batch=\"newest\", subset='GB',\n",
    "    reload_raw=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing MCS\n",
    "\n",
    "After processing the EPC data, it has to be uploaded to S3 again for further processing. In the future, this will happen automatically.\n",
    "In order for the following code to work, you should at least upload the following file to the S3 asf-core-data bucket: `LOCAL_DATA_DIR/BATCH_NAME/EPC_GB_preprocessed.csv`\n",
    "\n",
    "You can do this using a command as the following in your terminal:\n",
    "\n",
    "`aws s3 cp LOCAL_DATA_DIR/outputs/EPC/preprocessed_data/2022_Q3_complete/EPC_GB_preprocessed.csv s3://asf-core-data/outputs/EPC/preprocessed_data/2022_Q3_complete/`\n",
    "\n",
    "\n",
    "**Note:**\n",
    "An additional step will be added here or included in `generate_and_save_mcs()`. We will need to process the MCS historical installer data and add the unique installation ID to the MCS installations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to process MCS data and join it with EPC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installations files\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2021.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q1.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q2.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q3.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q4.xlsx\n",
      "\n",
      "Installer files\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q1.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installer_information_2022_04_06.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installer_information_2022_07_25.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installers.xlsx\n",
      "Number of records before removing duplicates: 178248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/mcs/generate_mcs_data.py:136: UserWarning: Not all installation file columns are the same.\n",
      "  warnings.warn(\"Not all installation file columns are the same.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after removing duplicates: 178200\n",
      "Shape of loaded data: (176524, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/mcs/process/process_mcs_installations.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hps[\"cluster\"].loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in S3: /outputs/MCS/mcs_installations_230315.csv\n",
      "Getting EPC data...\n"
     ]
    }
   ],
   "source": [
    "# Get MCS and join with MCS\n",
    "generate_and_save_mcs(verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the EPC and MCS\n",
    "\n",
    "Finally, we load the EPC data and merge it with the MCS installations data for computing the best approximation for a heat pump installation date. You can also load the data from 'S3' insteadl of the local data dir, but if you have it downloaded it's faster.\n",
    "\n",
    "All these steps are summarised in the function `merging_pipeline()` in `merge_proc_datasets.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed EPC data \n",
    "prep_epc = load_preprocessed_epc_data(data_path=\"S3\", version='preprocessed',\n",
    "                                       #usecols=['UPRN', 'INSPECTION_DATE', 'HP_INSTALLED', 'HP_TYPE'],  # use fewer fields for testing to save time\n",
    "                                       batch='newest'\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more precise estimations for heat pump installation dates via MCS data\n",
    "epc_with_MCS_dates = install_date_computation.compute_hp_install_date(\n",
    "    prep_epc\n",
    ")\n",
    "\n",
    "epc_with_MCS_dates.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EPC data with enhanced installation dates can then be merged with MCS installation data. This will standardise features such as HP_INSTALLED and HP_TYPE.\n",
    "\n",
    "**Note**: We're excluding two missing features (\"company_unique_id\", \"installer_name\") until the final merges are complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_mcs_processed = merge_proc_datasets.add_mcs_installations_data(epc_with_MCS_dates, usecols=[\n",
    "        \"UPRN\",\n",
    "        \"commission_date\",\n",
    "        \"capacity\",\n",
    "        \"estimated_annual_generation\",\n",
    "        \"flow_temp\",\n",
    "        \"tech_type\",\n",
    "        \"scop\",\n",
    "        \"design\",\n",
    "        \"product_name\",\n",
    "        \"manufacturer\",\n",
    "        \"cost\"\n",
    "    ], verbose=True)\n",
    "epc_mcs_processed.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! This will fail until merge conflicts are resolved !\n",
    "\n",
    "This section will be tested and revised after the final merges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge EPC/MCS with MCS installers \n",
    "epc_mcs_complete = merge_proc_datasets.add_mcs_installer_data(\n",
    "    epc_mcs_processed)\n",
    "\n",
    "epc_mcs_complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat postcode field to include no space\n",
    "epc_mcs_complete = data_cleaning.reformat_postcode(\n",
    "    epc_mcs_complete, postcode_var_name=\"POSTCODE\", white_space=\"remove\"\n",
    ")\n",
    "epc_mcs_complete['POSTCODE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_mcs_combined = merge_proc_datasets.merging_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('asf_core_data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "151bc73aaa639fad610cb4b2d60afec3c77157d89b4c3022086af37771d09181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
