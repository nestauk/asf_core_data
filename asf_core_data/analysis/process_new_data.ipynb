{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for producing processed EPC and MCS data and merging them into one table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the asf-core-data repo for the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-19 16:47:07,947 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n",
      "2023-03-19 16:47:08,718 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/Users/juliasuter/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/juliasuter/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/juliasuter/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "from asf_core_data.config import base_config\n",
    "\n",
    "from asf_core_data import generate_and_save_mcs\n",
    "from asf_core_data import load_preprocessed_epc_data\n",
    "\n",
    "from asf_core_data.getters.epc import data_batches\n",
    "from asf_core_data.getters.data_getters import download_core_data, load_s3_data, save_to_s3\n",
    "from asf_core_data.pipeline.preprocessing import data_cleaning\n",
    "\n",
    "from asf_core_data.pipeline.preprocessing import preprocess_epc_data\n",
    "from asf_core_data.pipeline.data_joining import install_date_computation, merge_proc_datasets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing EPC\n",
    "\n",
    "Currently, we're still handling the EPC processing by downloading and processing it locally. In the future, this will be done directly via S3. \n",
    "For now, we need to download the raw EPC data into our local data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_DIR = '/path/to/data/dir'\n",
    "\n",
    "\n",
    "if not os.path.exists(LOCAL_DATA_DIR):\n",
    "    os.makedirs(LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_core_data('epc_raw', LOCAL_DATA_DIR, batch='newest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether newest batch shows up a newest in local data dir\n",
    "print(\"Local input dir\\n---------------\")\n",
    "print(\"Available batches:\", data_batches.get_all_batch_names(data_path=LOCAL_DATA_DIR, check_folder='inputs'))\n",
    "print(\"Newest batch:\", data_batches.get_most_recent_epc_batch(data_path=LOCAL_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process new batch of EPC data\n",
    "epc_full = preprocess_epc_data.load_and_preprocess_epc_data(\n",
    "    data_path=LOCAL_DATA_DIR, batch=\"newest\", subset='GB',\n",
    "    reload_raw=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After processing the EPC data, it has to be uploaded to S3 again for further processing. In the future, this will happen automatically.\n",
    "In order for the following code to work, you should at least upload the following file to the S3 asf-core-data bucket: `LOCAL_DATA_DIR/BATCH_NAME/EPC_GB_preprocessed.csv`\n",
    "\n",
    "You can do this using a command as the following in your terminal:\n",
    "\n",
    "`aws s3 cp LOCAL_DATA_DIR/outputs/EPC/preprocessed_data/2022_Q3_complete/EPC_GB_preprocessed.csv s3://asf-core-data/outputs/EPC/preprocessed_data/2022_Q3_complete/`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing MCS\n",
    "\n",
    "Next, we have to process MCS data.\n",
    "\n",
    "Note that the following two commands might not run correctly in Jupyter notebook because of the COMPANIES_HOUSE_API_KEY. \n",
    "\n",
    "If the API KEY is set up correctly according to the instructions [here](https://github.com/nestauk/asf_core_data/pull/37), it will at least run if executed in a terminal: : `python generate_mcs_data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MCS and join with MCS\n",
    "uk_geo_data = load_s3_data('asf-core-data', base_config.POSTCODE_TO_COORD_PATH)\n",
    "generate_and_save_mcs(uk_geo_data, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the EPC and MCS\n",
    "\n",
    "Finally, we merge the EPC and MCS installations and installers data into one dataframe.\n",
    "\n",
    "The output is a complete datafarame with all EPC records (dedupl) and MCS installations and installers.\n",
    "We use outer merges to avoid losing data, creating NaN values for missing records.\n",
    "\n",
    "    - Load EPC data\n",
    "    - Get best approximation for installation date\n",
    "    - Merge with MCS installations and reformatting\n",
    "    - Merge with MCS installers\n",
    "    - Reformat postcode and geographies\n",
    "    - Save output to S3\n",
    "\n",
    "All these steps are summarised in the function `merging_pipeline()` in `merge_proc_datasets.py`. \n",
    "Running the full pipeline in a jupyter notebook can lead to a Kernel crash, so executing in a terminal is safer: `python merge_proc_datasets.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-19 16:47:24,851 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Load the processed EPC data \n",
    "prep_epc = load_preprocessed_epc_data(data_path=\"S3\", version='preprocessed', batch='newest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"FIRST_HP_MENTION\"] = df[identifier].map(dict(first_hp_mention))\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"MCS_AVAILABLE\"] = ~df[\"HP_INSTALL_DATE\"].isna()\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HAS_HP_AT_SOME_POINT\"] = ~df[\"FIRST_HP_MENTION\"].isna()\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ARTIFICIALLY_DUPL\"] = False\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"EPC HP entry before MCS\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:240: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:243: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:254: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"No EPC HP entry after MCS\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:262: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19047896, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more precise estimations for heat pump installation dates via MCS data\n",
    "epc_with_MCS_dates = install_date_computation.compute_hp_install_date(\n",
    "    prep_epc\n",
    ")\n",
    "\n",
    "epc_with_MCS_dates.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EPC data with enhanced installation dates can then be merged with MCS installation data. This will standardise features such as HP_INSTALLED and HP_TYPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPC (19047896, 65)\n",
      "MCS (178271, 15)\n",
      "MCS (EPC matched) (146949, 15)\n",
      "MCS (EPC unmatched) (31322, 15)\n",
      "EPC and MCS merged (19086463, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['BUILDING_REFERENCE_NUMBER', 'UPRN', 'ADDRESS1', 'ADDRESS2', 'POSTCODE',\n",
       "       'INSPECTION_DATE', 'ENERGY_CONSUMPTION_CURRENT', 'TOTAL_FLOOR_AREA',\n",
       "       'CURRENT_ENERGY_EFFICIENCY', 'CURRENT_ENERGY_RATING',\n",
       "       'POTENTIAL_ENERGY_RATING', 'CO2_EMISS_CURR_PER_FLOOR_AREA',\n",
       "       'WALLS_DESCRIPTION', 'WALLS_ENERGY_EFF', 'ROOF_DESCRIPTION',\n",
       "       'ROOF_ENERGY_EFF', 'FLOOR_DESCRIPTION', 'FLOOR_ENERGY_EFF',\n",
       "       'WINDOWS_DESCRIPTION', 'WINDOWS_ENERGY_EFF', 'MAINHEAT_DESCRIPTION',\n",
       "       'MAINHEAT_ENERGY_EFF', 'MAINHEATC_ENERGY_EFF', 'SECONDHEAT_DESCRIPTION',\n",
       "       'HOTWATER_DESCRIPTION', 'HOT_WATER_ENERGY_EFF', 'LIGHTING_DESCRIPTION',\n",
       "       'LIGHTING_ENERGY_EFF', 'CO2_EMISSIONS_CURRENT', 'CONSTRUCTION_AGE_BAND',\n",
       "       'LOW_ENERGY_LIGHTING', 'FLOOR_LEVEL', 'GLAZED_AREA',\n",
       "       'NUMBER_HABITABLE_ROOMS', 'LOCAL_AUTHORITY_LABEL', 'MAINS_GAS_FLAG',\n",
       "       'MAIN_HEATING_CONTROLS', 'ENERGY_TARIFF', 'MULTI_GLAZE_PROPORTION',\n",
       "       'GLAZED_TYPE', 'PHOTO_SUPPLY', 'SOLAR_WATER_HEATING_FLAG', 'TENURE',\n",
       "       'TRANSACTION_TYPE', 'BUILT_FORM', 'PROPERTY_TYPE', 'COUNTRY', 'LMK_KEY',\n",
       "       'LOCAL_AUTHORITY', 'N_SAME_UPRN_ENTRIES', 'HEATING_SYSTEM',\n",
       "       'HEATING_FUEL', 'HP_INSTALLED', 'HP_TYPE', 'CURR_ENERGY_RATING_NUM',\n",
       "       'ENERGY_RATING_CAT', 'DIFF_POT_ENERGY_RATING', 'HP_INSTALL_DATE',\n",
       "       'FIRST_HP_MENTION', 'MCS_AVAILABLE', 'HAS_HP_AT_SOME_POINT',\n",
       "       'ARTIFICIALLY_DUPL', 'EPC HP entry before MCS',\n",
       "       'No EPC HP entry after MCS', 'EPC_AVAILABLE', 'commission_date',\n",
       "       'capacity', 'estimated_annual_generation', 'installer_name',\n",
       "       'tech_type', 'design', 'cost', 'product_name', 'manufacturer',\n",
       "       'flow_temp', 'scop', 'company_unique_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epc_mcs_processed = merge_proc_datasets.add_mcs_installations_data(epc_with_MCS_dates, verbose=True)\n",
    "epc_mcs_processed.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the MCS installer data and merge using the installer ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BUILDING_REFERENCE_NUMBER', 'UPRN', 'ADDRESS1', 'ADDRESS2', 'POSTCODE',\n",
       "       'INSPECTION_DATE', 'ENERGY_CONSUMPTION_CURRENT', 'TOTAL_FLOOR_AREA',\n",
       "       'CURRENT_ENERGY_EFFICIENCY', 'CURRENT_ENERGY_RATING',\n",
       "       'POTENTIAL_ENERGY_RATING', 'CO2_EMISS_CURR_PER_FLOOR_AREA',\n",
       "       'WALLS_DESCRIPTION', 'WALLS_ENERGY_EFF', 'ROOF_DESCRIPTION',\n",
       "       'ROOF_ENERGY_EFF', 'FLOOR_DESCRIPTION', 'FLOOR_ENERGY_EFF',\n",
       "       'WINDOWS_DESCRIPTION', 'WINDOWS_ENERGY_EFF', 'MAINHEAT_DESCRIPTION',\n",
       "       'MAINHEAT_ENERGY_EFF', 'MAINHEATC_ENERGY_EFF', 'SECONDHEAT_DESCRIPTION',\n",
       "       'HOTWATER_DESCRIPTION', 'HOT_WATER_ENERGY_EFF', 'LIGHTING_DESCRIPTION',\n",
       "       'LIGHTING_ENERGY_EFF', 'CO2_EMISSIONS_CURRENT', 'CONSTRUCTION_AGE_BAND',\n",
       "       'LOW_ENERGY_LIGHTING', 'FLOOR_LEVEL', 'GLAZED_AREA',\n",
       "       'NUMBER_HABITABLE_ROOMS', 'LOCAL_AUTHORITY_LABEL', 'MAINS_GAS_FLAG',\n",
       "       'MAIN_HEATING_CONTROLS', 'ENERGY_TARIFF', 'MULTI_GLAZE_PROPORTION',\n",
       "       'GLAZED_TYPE', 'PHOTO_SUPPLY', 'SOLAR_WATER_HEATING_FLAG', 'TENURE',\n",
       "       'TRANSACTION_TYPE', 'BUILT_FORM', 'PROPERTY_TYPE', 'COUNTRY', 'LMK_KEY',\n",
       "       'LOCAL_AUTHORITY', 'N_SAME_UPRN_ENTRIES', 'HEATING_SYSTEM',\n",
       "       'HEATING_FUEL', 'HP_INSTALLED', 'HP_TYPE', 'CURR_ENERGY_RATING_NUM',\n",
       "       'ENERGY_RATING_CAT', 'DIFF_POT_ENERGY_RATING', 'HP_INSTALL_DATE',\n",
       "       'FIRST_HP_MENTION', 'MCS_AVAILABLE', 'HAS_HP_AT_SOME_POINT',\n",
       "       'ARTIFICIALLY_DUPL', 'EPC HP entry before MCS',\n",
       "       'No EPC HP entry after MCS', 'EPC_AVAILABLE', 'commission_date',\n",
       "       'capacity', 'estimated_annual_generation', 'installer_name',\n",
       "       'tech_type', 'design', 'cost', 'product_name', 'manufacturer',\n",
       "       'flow_temp', 'scop', 'company_unique_id', 'company_name',\n",
       "       'mcs_certificate_number', 'certification_body', 'latitude', 'longitude',\n",
       "       'effective_from', 'effective_to', 'biomass_certified',\n",
       "       'hydro_certified', 'micro_chp_certified', 'solar_pv_certified',\n",
       "       'wind_turbine_certified', 'solar_thermal_certified',\n",
       "       'battery_storage_certified', 'air_source_hp_certified',\n",
       "       'ground_water_source_hp_certified', 'hot_water_hp_certified',\n",
       "       'exhaust_air_hp_certified', 'gas_absorbtion_hp_certified',\n",
       "       'solar_assisted_hp_certified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge EPC/MCS with MCS installers \n",
    "epc_mcs_complete = merge_proc_datasets.add_mcs_installer_data(\n",
    "    epc_mcs_processed)\n",
    "\n",
    "epc_mcs_complete.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we standardise the postcode format and save the output to the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    EH224NH\n",
       "1    EH222JS\n",
       "2    EH259RU\n",
       "3    EH222LS\n",
       "4    EH222LN\n",
       "Name: POSTCODE, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformat postcode field to include no space\n",
    "epc_mcs_complete = data_cleaning.reformat_postcode(\n",
    "    epc_mcs_complete, postcode_var_name=\"POSTCODE\", white_space=\"remove\"\n",
    ")\n",
    "epc_mcs_complete['POSTCODE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final merged dataset\n",
    "save_to_s3(\n",
    "    base_config.BUCKET_NAME,\n",
    "    epc_mcs_complete,\n",
    "    base_config.EPC_MCS_MERGED_OUT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one:\n",
    "# epc_mcs_combined = merge_proc_datasets.merging_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": true
  },
  "kernelspec": {
   "display_name": "asf_core_data",
   "language": "python",
   "name": "asf_core_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "151bc73aaa639fad610cb4b2d60afec3c77157d89b4c3022086af37771d09181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
