{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for producing processed EPC and MCS data and merging them into one table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the asf-core-data repo for the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "from asf_core_data import generate_and_save_mcs\n",
    "from asf_core_data import load_preprocessed_epc_data\n",
    "\n",
    "from asf_core_data.getters.epc import data_batches\n",
    "from asf_core_data.getters.data_getters import download_core_data\n",
    "\n",
    "from asf_core_data.pipeline.preprocessing import preprocess_epc_data\n",
    "from asf_core_data.pipeline.data_joining import install_date_computation, merge_proc_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing EPC\n",
    "\n",
    "Currently, we're still handling the EPC processing by downloading and processing it locally. In the future, this will be done directly via S3. \n",
    "For now, we need to download the raw EPC data into our local data foler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_DIR = '/path/to/data/dir'\n",
    "\n",
    "\n",
    "if not os.path.exists(LOCAL_DATA_DIR):\n",
    "    os.makedirs(LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_core_data('epc_raw', LOCAL_DATA_DIR, batch='newest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local input dir\n",
      "---------------\n",
      "Available batches: ['2021_Q2_0721', '2022_Q1_complete', '2021_Q4_0721', '2020_Q3_1220', '2022_Q3_complete']\n",
      "Newest batch: 2022_Q3_complete\n"
     ]
    }
   ],
   "source": [
    "# Check whether newest batch shows up a newest in local data dir\n",
    "print(\"Local input dir\\n---------------\")\n",
    "print(\"Available batches:\", data_batches.get_all_batch_names(data_path=LOCAL_DATA_DIR, check_folder='inputs'))\n",
    "print(\"Newest batch:\", data_batches.get_most_recent_epc_batch(data_path=LOCAL_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process new batch of EPC data\n",
    "epc_full = preprocess_epc_data.load_and_preprocess_epc_data(\n",
    "    data_path=LOCAL_DATA_DIR, batch=\"newest\", subset='GB',\n",
    "    reload_raw=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing MCS\n",
    "\n",
    "After processing the EPC data, it has to be uploaded to S3 again for further processing. In the future, this will happen automatically.\n",
    "In order for the following code to work, you should at least upload the following file to the S3 asf-core-data bucket: `LOCAL_DATA_DIR/BATCH_NAME/EPC_GB_preprocessed.csv`\n",
    "\n",
    "You can do this using a command as the following in your terminal:\n",
    "\n",
    "`aws s3 cp LOCAL_DATA_DIR/outputs/EPC/preprocessed_data/2022_Q3_complete/EPC_GB_preprocessed.csv s3://asf-core-data/outputs/EPC/preprocessed_data/2022_Q3_complete/`\n",
    "\n",
    "\n",
    "**Note:**\n",
    "An additional step will be added here or included in `generate_and_save_mcs()`. We will need to process the MCS historical installer data and add the unique installation ID to the MCS installations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to process MCS data and join it with EPC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installations files\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2021.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q1.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q2.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q3.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q4.xlsx\n",
      "\n",
      "Installer files\n",
      "inputs/MCS/latest_raw_data/mcs_installations_2022_q1.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installer_information_2022_04_06.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installer_information_2022_07_25.xlsx\n",
      "inputs/MCS/latest_raw_data/mcs_installers.xlsx\n",
      "Number of records before removing duplicates: 178248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/mcs/generate_mcs_data.py:136: UserWarning: Not all installation file columns are the same.\n",
      "  warnings.warn(\"Not all installation file columns are the same.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after removing duplicates: 178200\n",
      "Shape of loaded data: (176524, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/mcs/process/process_mcs_installations.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hps[\"cluster\"].loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in S3: /outputs/MCS/mcs_installations_230315.csv\n",
      "Getting EPC data...\n",
      "Forming a matching...\n",
      "- Forming an index...\n",
      "- Forming a comparison...\n",
      "- Computing a matching...\n",
      "Joining the data...\n",
      "After joining:\n",
      "-----------------\n",
      "Total records: 277493\n",
      "Number matched with EPC: 246186\n",
      "\n",
      "\n",
      "Saved in S3: /outputs/MCS/mcs_installations_epc_full_230315.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/mcs/process/mcs_epc_joining.py:372: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  joined_df[\"last_epc_before_mcs\"].iloc[last_epc_before_mcs_indices] = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in S3: /outputs/MCS/mcs_installations_epc_most_relevant_230315.csv\n"
     ]
    }
   ],
   "source": [
    "# Get MCS and join with MCS\n",
    "generate_and_save_mcs(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the EPC and MCS\n",
    "\n",
    "Finally, we load the EPC data and merge it with the MCS installations data for computing the best approximation for a heat pump installation date. You can also load the data from 'S3' insteadl of the local data dir, but if you have it downloaded it's faster.\n",
    "\n",
    "All these steps are summarised in the function `merging_pipeline()` in `merge_proc_datasets.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 02:21:40,785 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Load the processed EPC data \n",
    "prep_epc = load_preprocessed_epc_data(data_path=\"S3\", version='preprocessed',\n",
    "                                       #usecols=['UPRN', 'INSPECTION_DATE', 'HP_INSTALLED', 'HP_TYPE'],  # use fewer fields for testing to save time\n",
    "                                       batch='newest'\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"FIRST_HP_MENTION\"] = df[identifier].map(dict(first_hp_mention))\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"MCS_AVAILABLE\"] = ~df[\"HP_INSTALL_DATE\"].isna()\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HAS_HP_AT_SOME_POINT\"] = ~df[\"FIRST_HP_MENTION\"].isna()\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ARTIFICIALLY_DUPL\"] = False\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"EPC HP entry before MCS\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:240: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:243: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:254: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"No EPC HP entry after MCS\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:262: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALLED\"] = np.where(\n",
      "/Users/juliasuter/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/install_date_computation.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"HP_INSTALL_DATE\"] = np.where(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19047896, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more precise estimations for heat pump installation dates via MCS data\n",
    "epc_with_MCS_dates = install_date_computation.compute_hp_install_date(\n",
    "    prep_epc\n",
    ")\n",
    "\n",
    "epc_with_MCS_dates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EPC data with enhanced installation dates can then be merged with MCS installation data. This will standardise features such as HP_INSTALLED and HP_TYPE.\n",
    "\n",
    "**Note**: We're excluding two missing features (\"company_unique_id\", \"installer_name\") until the final merges are complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPC (19047896, 65)\n",
      "MCS (176524, 13)\n",
      "MCS (EPC matched) (145217, 13)\n",
      "MCS (EPC unmatched) (31307, 13)\n",
      "EPC and MCS merged (19085300, 75)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['BUILDING_REFERENCE_NUMBER', 'UPRN', 'ADDRESS1', 'ADDRESS2', 'POSTCODE',\n",
       "       'INSPECTION_DATE', 'ENERGY_CONSUMPTION_CURRENT', 'TOTAL_FLOOR_AREA',\n",
       "       'CURRENT_ENERGY_EFFICIENCY', 'CURRENT_ENERGY_RATING',\n",
       "       'POTENTIAL_ENERGY_RATING', 'CO2_EMISS_CURR_PER_FLOOR_AREA',\n",
       "       'WALLS_DESCRIPTION', 'WALLS_ENERGY_EFF', 'ROOF_DESCRIPTION',\n",
       "       'ROOF_ENERGY_EFF', 'FLOOR_DESCRIPTION', 'FLOOR_ENERGY_EFF',\n",
       "       'WINDOWS_DESCRIPTION', 'WINDOWS_ENERGY_EFF', 'MAINHEAT_DESCRIPTION',\n",
       "       'MAINHEAT_ENERGY_EFF', 'MAINHEATC_ENERGY_EFF', 'SECONDHEAT_DESCRIPTION',\n",
       "       'HOTWATER_DESCRIPTION', 'HOT_WATER_ENERGY_EFF', 'LIGHTING_DESCRIPTION',\n",
       "       'LIGHTING_ENERGY_EFF', 'CO2_EMISSIONS_CURRENT', 'CONSTRUCTION_AGE_BAND',\n",
       "       'LOW_ENERGY_LIGHTING', 'FLOOR_LEVEL', 'GLAZED_AREA',\n",
       "       'NUMBER_HABITABLE_ROOMS', 'LOCAL_AUTHORITY_LABEL', 'MAINS_GAS_FLAG',\n",
       "       'MAIN_HEATING_CONTROLS', 'ENERGY_TARIFF', 'MULTI_GLAZE_PROPORTION',\n",
       "       'GLAZED_TYPE', 'PHOTO_SUPPLY', 'SOLAR_WATER_HEATING_FLAG', 'TENURE',\n",
       "       'TRANSACTION_TYPE', 'BUILT_FORM', 'PROPERTY_TYPE', 'COUNTRY', 'LMK_KEY',\n",
       "       'LOCAL_AUTHORITY', 'N_SAME_UPRN_ENTRIES', 'HEATING_SYSTEM',\n",
       "       'HEATING_FUEL', 'HP_INSTALLED', 'HP_TYPE', 'CURR_ENERGY_RATING_NUM',\n",
       "       'ENERGY_RATING_CAT', 'DIFF_POT_ENERGY_RATING', 'HP_INSTALL_DATE',\n",
       "       'FIRST_HP_MENTION', 'MCS_AVAILABLE', 'HAS_HP_AT_SOME_POINT',\n",
       "       'ARTIFICIALLY_DUPL', 'EPC HP entry before MCS',\n",
       "       'No EPC HP entry after MCS', 'EPC_AVAILABLE', 'commission_date',\n",
       "       'capacity', 'estimated_annual_generation', 'tech_type', 'design',\n",
       "       'cost', 'product_name', 'manufacturer', 'flow_temp', 'scop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epc_mcs_processed = merge_proc_datasets.add_mcs_installations_data(epc_with_MCS_dates, usecols=[\n",
    "        \"UPRN\",\n",
    "        \"commission_date\",\n",
    "        \"capacity\",\n",
    "        \"estimated_annual_generation\",\n",
    "        \"flow_temp\",\n",
    "        \"tech_type\",\n",
    "        \"scop\",\n",
    "        \"design\",\n",
    "        \"product_name\",\n",
    "        \"manufacturer\",\n",
    "        \"cost\"\n",
    "    ], verbose=True)\n",
    "epc_mcs_processed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! This will fail until merge conflicts are resolved !\n",
    "\n",
    "This section will be tested and revised after the final merges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'company_unique_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge EPC/MCS with MCS installers \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m epc_mcs_complete \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_proc_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_mcs_installer_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepc_mcs_processed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m epc_mcs_complete\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/Documents/repositories/asf_core_data/asf_core_data/pipeline/data_joining/merge_proc_datasets.py:165\u001b[0m, in \u001b[0;36madd_mcs_installer_data\u001b[0;34m(df, usecols)\u001b[0m\n\u001b[1;32m    159\u001b[0m mcs_instllr_data \u001b[38;5;241m=\u001b[39m data_getters\u001b[38;5;241m.\u001b[39mload_s3_data(\n\u001b[1;32m    160\u001b[0m     base_config\u001b[38;5;241m.\u001b[39mBUCKET_NAME, newest_hist_inst_batch, usecols\u001b[38;5;241m=\u001b[39musecols\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m mcs_instllr_data\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostcode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTCODE\u001b[39m\u001b[38;5;124m\"\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 165\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmcs_instllr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompany_unique_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstaller_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompany_unique_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompany_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:9351\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9332\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9333\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   9334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9347\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   9348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9349\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m-> 9351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9352\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9360\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9361\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9365\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    696\u001b[0m (\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1110\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(rk)\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1110\u001b[0m     left_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1111\u001b[0m     join_names\u001b[38;5;241m.\u001b[39mappend(lk)\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:1840\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1838\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'company_unique_id'"
     ]
    }
   ],
   "source": [
    "# Merge EPC/MCS with MCS installers \n",
    "epc_mcs_complete = merge_proc_datasets.add_mcs_installer_data(\n",
    "    epc_mcs_processed)\n",
    "\n",
    "epc_mcs_complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat postcode field to include no space\n",
    "epc_mcs_complete = data_cleaning.reformat_postcode(\n",
    "    epc_mcs_complete, postcode_var_name=\"POSTCODE\", white_space=\"remove\"\n",
    ")\n",
    "epc_mcs_complete['POSTCODE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 11:51:27,171 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "epc_mcs_combined = merge_proc_datasets.merging_pipeline()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "151bc73aaa639fad610cb4b2d60afec3c77157d89b4c3022086af37771d09181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
